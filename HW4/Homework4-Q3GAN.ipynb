{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 4 - Part3 : GANs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this homework you will build a deep generative model of binary images (MNIST) using variational autoencoders and generative adversarial networks.\n",
    "The original VAE paper can be found [here](https://arxiv.org/abs/1312.6114) and GANs [here](https://arxiv.org/abs/1406.2661), and there are many excellent tutorials\n",
    "online, e.g. [here](https://arxiv.org/abs/1606.05908) and [here](https://jaan.io/what-is-variational-autoencoder-vae-tutorial/)\n",
    "\n",
    "**For this homework there will not be a Kaggle submission**\n",
    "\n",
    "## Goals\n",
    "\n",
    "\n",
    "1. Build a discrete deep generative model of binary digits (MNIST) using variational autoencoders\n",
    "2. Examine the learned latent space with visualizations \n",
    "3. Build a conditinous deep geneartive model using generative adversarial networks.\n",
    "4. Additionally extend the above in any way, for example by :\n",
    "    - using better encoder/decoders (e.g. CNN as the encoder, PixelCNN as the decoder. Description of PixelCNN \n",
    "    can be found [here](https://arxiv.org/abs/1601.06759))\n",
    "    - using different variational families, e.g. with [normalizing flows](https://arxiv.org/abs/1505.05770), \n",
    "    [inverse autoregressive flows](https://arxiv.org/pdf/1606.04934.pdf), \n",
    "    [hierarchical models](https://arxiv.org/pdf/1602.02282.pdf)\n",
    "    - comparing with stochastic variational inference (i.e. where your variational parameters are randomly initialized and\n",
    "    then updated with gradient ascent on the ELBO\n",
    "    - or your own extension.\n",
    "\n",
    "For your encoder/decoder, we suggest starting off with simple models (e.g. 2-layer MLP with ReLUs).\n",
    "\n",
    "Consult the papers provided for hyperparameters, and the course notes for formal definitions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "This notebook provides a working definition of the setup of the problem itself. Feel free to construct your models inline, or use an external setup (preferred) to build your system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, as always, let's download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "train_dataset = datasets.MNIST(root='./data/',\n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    "test_dataset = datasets.MNIST(root='./data/',\n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "train_dataset[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default MNIST gives grayscale values between [0,1]. Since we are modeling binary images, we have to turn these\n",
    "into binary values, i.e. $\\{0,1\\}^{784}$). A standard way to do this is to interpret the grayscale values as \n",
    "probabilities and sample Bernoulli random vectors based on these probabilities. (Note you should not do this for GANs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(3435)\n",
    "train_img = torch.stack([torch.bernoulli(d[0]) for d in train_dataset])\n",
    "train_label = torch.LongTensor([d[1] for d in train_dataset])\n",
    "test_img = torch.stack([torch.bernoulli(d[0]) for d in test_dataset])\n",
    "test_label = torch.LongTensor([d[1] for d in test_dataset])\n",
    "print(train_img[0])\n",
    "print(train_img.size(), train_label.size(), test_img.size(), test_label.size())\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST does not have an official train dataset. So we will use the last 10000 training points as your validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img = train_img[-10000:].clone()\n",
    "val_label = train_label[-10000:].clone()\n",
    "train_img = train_img[:10000]\n",
    "train_label = train_label[:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the dataloader to split into batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.utils.data.TensorDataset(train_img, train_label)\n",
    "val = torch.utils.data.TensorDataset(val_img, val_label)\n",
    "test = torch.utils.data.TensorDataset(test_img, test_label)\n",
    "BATCH_SIZE = 100\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for datum in train_loader:\n",
    "    img, label = datum\n",
    "    print(img.size(), label.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great now we are ready to begin modeling. Performance-wise, you want tune your hyperparameters based on the **evidence lower bound (ELBO)**. Recall that the ELBO is given by:\n",
    "\n",
    "$$ELBO = \\mathbb{E}_{q(\\mathbf{z} ; \\lambda)} [\\log p(\\mathbf{x} \\,|\\,\\mathbf{z} ; \\theta)] - \\mathbb{KL}[q(\\mathbf{z};\\lambda) \\, \\Vert \\, p(\\mathbf{z})]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variational parameters are given by running the encoder over the input, i..e. $\\lambda = encoder(\\mathbf{x};\\phi)$. The generative model (i.e. decoder) is parameterized by $\\theta$. Since we are working with binarized digits, $\\log p(x \\, | \\, \\mathbf{z} ; \\theta)$ is given by:\n",
    "\n",
    "$$ \\log p(x \\, | \\, \\mathbf{z} ; \\theta) = \\sum_{i=1}^{784} \\log \\sigma(\\mathbf{h})_{i} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\mathbf{h}$ is the final layer of the generative model (i.e. 28*28 = 784 dimensionval vector), and $\\sigma(\\cdot)$ is the sigmoid function. \n",
    "\n",
    "For the baseline model in this assignment you will be using a spherical normal prior, i.e. $p(\\mathbf{z}) = \\mathcal{N}(\\mathbf{0}, \\mathbf{I})$. The variational family will also be normal, i.e. $q(\\mathbf{z} ; \\lambda) = \\mathcal{N}(\\boldsymbol{\\mu}, \\log \\boldsymbol \\sigma^2)$ (here we will work with normal families with diagonal covariance). The KL-divergence between the variational posterior $q(\\mathbf{z})$ and the prior $p(\\mathbf{z})$ has a closed-form analytic solution, which is available in the original VAE paper referenced above. (If you are using the torch distributions package they will automatically calculate it for you, however you will need to use pytorch 0.4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Baseline GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as img_utils\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data/',\n",
    "                            train=True, \n",
    "                            transform=transform,\n",
    "                            download=True)\n",
    "test_dataset = datasets.MNIST(root='./data/',\n",
    "                           train=False, \n",
    "                           transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(3435)\n",
    "train_img = torch.stack([d[0] for d in train_dataset])\n",
    "train_label = torch.LongTensor([d[1] for d in train_dataset])\n",
    "test_img = torch.stack([d[0] for d in test_dataset])\n",
    "test_label = torch.LongTensor([d[1] for d in test_dataset])\n",
    "print(train_img.size(), train_label.size(), test_img.size(), test_label.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_img = train_img[-10000:].clone()\n",
    "val_label = train_label[-10000:].clone()\n",
    "train_img = train_img[:10000]\n",
    "train_label = train_label[:10000]\n",
    "train = torch.utils.data.TensorDataset(train_img, train_label)\n",
    "val = torch.utils.data.TensorDataset(val_img, val_label)\n",
    "test = torch.utils.data.TensorDataset(test_img, test_label)\n",
    "BATCH_SIZE = 100\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for datum in train_loader:\n",
    "    img, label = datum\n",
    "    print(img.size(), label.size())\n",
    "    print(img[3][0].shape)\n",
    "    plt.imshow(img[3][0], cmap='gray')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "from torch.autograd import Variable as V\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Normal\n",
    "from torch.distributions.kl import kl_divergence\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 64\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, output_size=28*28):\n",
    "        super(Generator, self).__init__()\n",
    "        self.linear1 = nn.Linear(LATENT_DIM, 100)\n",
    "        self.linear2 = nn.Linear(100, output_size)\n",
    "        \n",
    "    def forward(self, z):\n",
    "        return F.tanh(self.linear2(F.relu(self.linear1(z))))\n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, output_size=28*28):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.linear1 = nn.Linear(output_size, 100)\n",
    "        self.linear2 = nn.Linear(100, 1)\n",
    "\n",
    "    def forward(self, point):\n",
    "        return F.sigmoid(self.linear2(F.relu(self.linear1(point))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator()\n",
    "D = Discriminator()\n",
    "learning_rate = 0.01\n",
    "optim_gen = torch.optim.SGD(G.parameters(), lr=learning_rate)\n",
    "optim_disc = torch.optim.SGD(D.parameters(), lr=learning_rate)\n",
    "seed_distribution = Normal(V(torch.zeros(BATCH_SIZE, LATENT_DIM)), \n",
    "                           V(torch.ones(BATCH_SIZE, LATENT_DIM)))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "output_arr = torch.zeros((NUM_EPOCHS, 1, 28, 28))\n",
    "gen_loss = [] \n",
    "disc_loss = [] \n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    total_gen_loss = 0\n",
    "    total_disc_loss = 0\n",
    "    num_batches = 0 \n",
    "    for datum in train_loader:\n",
    "        img, label = datum\n",
    "        \n",
    "        # Grad real\n",
    "        # -E[log(D(x))]\n",
    "        optim_disc.zero_grad()\n",
    "        optim_gen.zero_grad()\n",
    "        x_real = V(img).view(-1, 784)\n",
    "        d = D(x_real)\n",
    "        loss_a = 0.5 * -d.log().mean()\n",
    "        loss_a.backward()\n",
    "        \n",
    "        # Grad fake\n",
    "        # -E[log(1 - D(G(z)) )]\n",
    "        seed = seed_distribution.sample()\n",
    "        x_fake = G(seed)\n",
    "    \n",
    "        d = D(x_fake.detach())        \n",
    "        loss_b = 0.5 * -(1 - d + 1e-10).log().mean()\n",
    "        loss_b.backward()\n",
    "        optim_disc.step()\n",
    "        total_disc_loss += loss_a.data[0] + loss_b.data[0]\n",
    "\n",
    "        # Grad generator\n",
    "        # E[log(1 - D(G(z)))]\n",
    "        optim_disc.zero_grad()\n",
    "        # No detach here.\n",
    "        d = D(x_fake)\n",
    "        loss_c = (1 - d + 1e-10).log().mean()\n",
    "        #loss_c = -(d + 1e-10).log().mean()\n",
    "        loss_c.backward()        \n",
    "        optim_gen.step()    \n",
    "        total_gen_loss += loss_c.data[0]\n",
    "        \n",
    "        num_batches += 1 \n",
    "    \n",
    "    #show fake \n",
    "    disp_arr = x_fake.detach()[0]\n",
    "    output_arr[epoch] = disp_arr.view(1, 28, 28)\n",
    "    disc_loss.append(float(total_disc_loss[0]))\n",
    "    gen_loss.append(float(total_gen_loss[0]))\n",
    "    if epoch % 10 == 0: \n",
    "        print(epoch, total_disc_loss[0] /  num_batches, total_gen_loss[0] / num_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.yticks(np.arange(15,10*30+15,30), ('0', '10', '20', '30', '40', '50', '60', '70', '80', '90' ))\n",
    "plt.xticks(np.arange(15,10*30+15,30), ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9' ))\n",
    "show(output_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(NUM_EPOCHS), gen_loss, label ='generator loss')\n",
    "plt.plot(range(NUM_EPOCHS), disc_loss, label ='discriminator loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
